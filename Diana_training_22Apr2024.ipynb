{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
   "id": "b97c9183",
=======
   "id": "d5f35232",
>>>>>>> 9f05f1770da140b7368bbc2ced4b87078c77adf4
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Written by Diana Lewis\n",
    "## Code edited and debugged by Matthew Miller\n",
    "## Additional help from ChatGPT and Label Studio documentation\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers, models \n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, ZeroPadding2D, Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from torchvision import transforms as T\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from keras import backend as K  \n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "id": "57a882d2",
   "metadata": {},
=======
   "execution_count": 2,
   "id": "57bdd442",
   "metadata": {
    "scrolled": false
   },
>>>>>>> 9f05f1770da140b7368bbc2ced4b87078c77adf4
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m resized_images, disc_masks, cup_masks \u001b[38;5;241m=\u001b[39m read_images_and_masks(folder_path)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Display the first image and its corresponding masks\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images:\n\u001b[1;32m     39\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Display original image\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "def read_images_and_masks(folder_path):\n",
    "    images = []\n",
    "    disc_masks = []\n",
    "    cup_masks = []\n",
    "\n",
    "    # Get list of files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Sort files to ensure they are read in the correct order\n",
    "    files.sort()\n",
    "\n",
    "    for file in files:\n",
    "        if file.startswith('image_'):\n",
    "            # Read and append image\n",
    "            image_path = os.path.join(folder_path, file)\n",
    "            image = cv2.imread(image_path)\n",
    "            images.append(image)\n",
    "        elif file.startswith('optic_disc_mask_'):\n",
    "            # Read and append optic disc mask\n",
    "            mask_path = os.path.join(folder_path, file)\n",
    "            disc_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            disc_masks.append(disc_mask)\n",
    "        elif file.startswith('optic_cup_mask_'):\n",
    "            # Read and append optic cup mask\n",
    "            mask_path = os.path.join(folder_path, file)\n",
    "            cup_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            cup_masks.append(cup_mask)\n",
    "\n",
    "    return images, disc_masks, cup_masks\n",
    "\n",
    "# Define the path to the folder containing the images and masks\n",
    "folder_path = 'Glaucoma_Balanced_Dataset/Diana_Output'\n",
    "\n",
    "# Read images and masks\n",
    "resized_images, disc_masks, cup_masks = read_images_and_masks(folder_path)\n",
    "\n",
    "# Display the first image and its corresponding masks\n",
    "if resized_images:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Display original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(resized_images[0], cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display optic disc mask\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(disc_masks[0], cmap='gray')\n",
    "    plt.title('Optic Disc Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display optic cup mask\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cup_masks[0], cmap='gray')\n",
    "    plt.title('Optic Cup Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images found in the specified folder.\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "5d15d922",
=======
   "execution_count": 3,
   "id": "a9d19869",
>>>>>>> 9f05f1770da140b7368bbc2ced4b87078c77adf4
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_masks_binary_adjusted = disc_masks\n",
    "cup_masks_binary_adjusted = cup_masks\n",
    "\n",
    "type(disc_masks_binary_adjusted)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "e0cacd02",
=======
   "execution_count": 4,
   "id": "60f4cadd",
>>>>>>> 9f05f1770da140b7368bbc2ced4b87078c77adf4
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmentation of Optic Disc \n",
    "# Define U-Net model\n",
    "def gnet_disc(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    \n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    conv6 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    \n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "   \n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    \n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(num_classes, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "input_shape = (256, 256, 3)\n",
    "num_classes = 1\n",
    "disc_model = gnet_disc(input_shape, num_classes)\n",
    "#model.summary()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "# Convert the lists to numpy arrays\n",
    "X = np.array(resized_images)\n",
    "y = np.array(disc_masks_binary_adjusted)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "# Convert y_train and y_val to float and expand the dimensions\n",
    "y_train = np.expand_dims(y_train, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "#y_train = np.squeeze(y_train, axis= 5)\n",
    "#y_val = np.squeeze(y_val, axis= 5)\n",
    "\n",
    "# Compile the model with Adam optimizer and reduced learning rate\n",
    "opt = optimizers.Adam(clipvalue=0.5)\n",
    "disc_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Add a learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# Data augmentation\n",
    "data_gen_args = dict(rotation_range=10,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     shear_range=0.1,\n",
    "                     zoom_range=0.1,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='reflect')\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "# Train generator\n",
    "image_generator = image_datagen.flow(X_train, batch_size=2, seed=seed)\n",
    "mask_generator = mask_datagen.flow(y_train, batch_size=2, seed=seed)\n",
    "\n",
    "# Combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095a300a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=<zip object at 0x0000023D67647000> (of type <class 'zip'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m images_per_epoch \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m history \u001b[38;5;241m=\u001b[39m disc_model\u001b[38;5;241m.\u001b[39mfit(train_generator, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val), \n\u001b[0;32m     25\u001b[0m                     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m disc_model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisc_segmentation_weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m disc_model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisc_segmentation_weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\__init__.py:113\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[1;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized data type: x=<zip object at 0x0000023D67647000> (of type <class 'zip'>)"
     ]
    }
   ],
   "source": [
    "# Define a function to calculate sensitivity and specificity\n",
    "#def calculate_metrics(y_true, y_pred):\n",
    "    #accuracy = accuracy_score(y_true, y_pred)\n",
    "    #precision = precision_score(y_true, y_pred)\n",
    "    #recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    #sensitivity = recall  # Sensitivity is the same as recall\n",
    "    #specificity = accuracy - (1 - precision)\n",
    "    \n",
    "    #return sensitivity, specificity\n",
    "    \n",
    "\n",
    "\n",
    "# Compute the total number of augmented images per epoch\n",
    "total_samples = len(X_train)  # Number of original images\n",
    "augmentation_factor = 15  # Number of augmented images generated per original image\n",
    "images_per_epoch = total_samples * augmentation_factor\n",
    "\n",
    "# Compute steps_per_epoch based on batch_size\n",
    "batch_size = 5 #CHANGE THIS \n",
    "steps_per_epoch = images_per_epoch // batch_size\n",
    "\n",
    "# Train the model\n",
    "history = disc_model.fit(train_generator, validation_data=(X_val, y_val), \n",
    "                    steps_per_epoch=steps_per_epoch, epochs=5, verbose=1)\n",
    "\n",
    "disc_model.save_weights(\"disc_segmentation_weights.h5\")\n",
    "disc_model.load_weights(\"disc_segmentation_weights.h5\")\n",
    "\n",
    "# Calculate sensitivity and specificity for each epoch\n",
    "def calculate_metrics_disc(y_true, y_pred):\n",
    "    #Assuming y_true and y_pred are numpy arrays\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    sensitivity  = tp / (tp + fn + K.epsilon())\n",
    "    specificity = tn / (tn + fp + K.epsilon())\n",
    "    \n",
    "    return sensitivity, specificity\n",
    "\n",
    "for i in range(len(history.history['val_loss'])):\n",
    "    y_pred = disc_model.predict(X_val)\n",
    "    sens, spec = calculate_metrics_cup(y_val, np.round(y_pred))  # Assuming y_pred needs to be rounded to 0 or 1\n",
    "    sensitivity.append(sens)\n",
    "    specificity.append(spec)\n",
    "    print(f\"Epoch {i+1}: Sensitivity = {sens}, Specificity = {spec}\")\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmentation of Optic Cup \n",
    "\n",
    "def gnet_cup(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(34,(4,2), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(34,(4,2), activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(4, 4))(conv1)\n",
    "    conv2 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(4, 4))(conv2)\n",
    "    conv3 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(4, 4))(conv3)\n",
    "    conv4 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(4, 4))(conv4)\n",
    "    conv5 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    up6 = UpSampling2D(size=(4, 4))(conv5)\n",
    "    \n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    conv6 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    up7 = UpSampling2D(size=(4, 4))(conv6)\n",
    "    \n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    up8 = UpSampling2D(size=(4, 4))(conv7)\n",
    "   \n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    up9 = UpSampling2D(size=(4, 4))(conv8)\n",
    "    \n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(34, (4,2), activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(34, (4,2), activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(num_classes, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "input_shape = (256, 256, 3)\n",
    "num_classes = 1\n",
    "cup_model = gnet_cup(input_shape, num_classes)\n",
    "#model.summary()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "# Convert the lists to numpy arrays\n",
    "X = np.array(resized_images)\n",
    "y = np.array(cup_masks_binary_adjusted)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "# Reshape X_train and X_val to include channel dimension\n",
    "#X_train = np.expand_dims(X_train, axis=-1)\n",
    "#X_val = np.expand_dims(X_val, axis=-1)\n",
    "\n",
    "# Reshape y_train and y_val to include channel dimension\n",
    "y_train = np.expand_dims(y_train, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "# Compile the model with Adam optimizer and reduced learning rate\n",
    "opt = optimizers.Adam(clipvalue=0.5)\n",
    "cup_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Add a learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# Data augmentation\n",
    "data_gen_args = dict(rotation_range=10,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     shear_range=0.1,\n",
    "                     zoom_range=0.1,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='reflect')\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "# Train generator\n",
    "image_generator = image_datagen.flow(X_train, batch_size=2, seed=seed)\n",
    "mask_generator = mask_datagen.flow(y_train, batch_size=2, seed=seed)\n",
    "\n",
    "# Combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "# Compute the total number of augmented images per epoch\n",
    "total_samples = len(X_train)  # Number of original images\n",
    "augmentation_factor = 15  # Number of augmented images generated per original image CHANGE THIS \n",
    "images_per_epoch = total_samples * augmentation_factor\n",
    "\n",
    "# Compute steps_per_epoch\n",
    "batch_size = 5 #CHANGE THIS \n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "\n",
    "\n",
    "# Train the model\n",
    "#history = model.fit(train_generator, validation_data=(X_val, y_val), epochs=10, verbose=1)\n",
    "# Train the model\n",
    "history = cup_model.fit(train_generator, validation_data=(X_val, y_val), \n",
    "                    steps_per_epoch=images_per_epoch // batch_size, epochs=5, verbose=1)\n",
    "\n",
    "# Save cup segmentation model weights\n",
    "cup_model.save_weights(\"cup_segmentation_weights.h5\")\n",
    "cup_model.load_weights(\"cup_segmentation_weights.h5\")\n",
    "\n",
    "# Calculate sensitivity and specificity for each epoch\n",
    "def calculate_metrics_cup(y_true, y_pred):\n",
    "    #Assuming y_true and y_pred are numpy arrays\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    sensitivity  = tp / (tp + fn + K.epsilon())\n",
    "    specificity = tn / (tn + fp + K.epsilon())\n",
    "    \n",
    "    return sensitivity, specificity\n",
    "\n",
    "for i in range(len(history.history['val_loss'])):\n",
    "    y_pred = cup_model.predict(X_val)\n",
    "    sens, spec = calculate_metrics_cup(y_val, np.round(y_pred))  # Assuming y_pred needs to be rounded to 0 or 1\n",
    "    sensitivity.append(sens)\n",
    "    specificity.append(spec)\n",
    "    print(f\"Epoch {i+1}: Sensitivity = {sens}, Specificity = {spec}\")\n",
    "\n",
    "\n",
    "#print(\"Last batch prediction shape:\", y_pred.shape)\n",
    "#print(\"Last batch prediction values:\", y_pred)\n",
    "#print(\"Last batch true labels shape:\", y_batch.shape)\n",
    "#print(\"Last batch true labels values:\", y_batch)\n",
    "\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output of segmentation masks to be used for classification\n",
    "# Predict cup masks for test images using cup segmentation model (cup_model)\n",
    "predicted_cup_masks = [cup_model.predict(np.expand_dims(image, axis=0)) for image in resized_images]\n",
    "\n",
    "# Predict disc masks for test images using disc segmentation model (disc_model)\n",
    "predicted_disc_masks = [disc_model.predict(np.expand_dims(image, axis=0)) for image in resized_images]\n",
    "\n",
    "def overlay_cup_mask(image, cup_mask, alpha=0.3):\n",
    "    # Resize mask to match image size\n",
    "    cup_mask = cv2.resize(cup_mask, (image.shape[1], image.shape[0]))\n",
    "    cup_mask = (cup_mask > 0.9).astype(np.uint8)  # Binarize mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cup_mask = cv2.morphologyEx(cup_mask, cv2.MORPH_OPEN, kernel)  # Apply morphological opening\n",
    "    overlay = image.copy()\n",
    "    overlay[cup_mask == 1] = (0, 255, 0)  # Green color for the cup mask\n",
    "    cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "    return image\n",
    "\n",
    "def overlay_disc_mask(image, disc_mask, alpha=0.3):\n",
    "    # Resize mask to match image size\n",
    "    disc_mask = cv2.resize(disc_mask, (image.shape[1], image.shape[0]))\n",
    "    disc_mask = (disc_mask > 0.1).astype(np.uint8)  # Binarize mask\n",
    "    \n",
    "    # Apply morphological closing to make the disc mask circular\n",
    "    disc_mask = cv2.morphologyEx(disc_mask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2)))\n",
    "    \n",
    "    overlay = image.copy()\n",
    "    overlay[disc_mask == 1] = (255, 0, 0)  # Red color for the disc mask\n",
    "    cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "    return image\n",
    "\n",
    "def display_overlay(original_image, image_with_masks, cup_mask, disc_mask):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(original_image)\n",
    "    plt.title('Original Image')\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(image_with_masks)\n",
    "    plt.title('Image with Overlayed Masks')\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(cup_mask, cmap='gray')\n",
    "    plt.title('Cup Mask')\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(disc_mask, cmap='gray')\n",
    "    plt.title('Disc Mask')\n",
    "    plt.show()\n",
    "\n",
    "# Display images with overlayed masks\n",
    "for i in range(len(resized_images)):\n",
    "    original_image = (resized_images[i] * 255).astype(np.uint8)\n",
    "    cup_mask = (predicted_cup_masks[i][0, :, :, 0] * 255).astype(np.uint8)\n",
    "    disc_mask = (predicted_disc_masks[i][0, :, :, 0] * 255).astype(np.uint8)\n",
    "    image_with_masks = overlay_cup_mask(original_image, cup_mask)\n",
    "    image_with_masks = overlay_disc_mask(image_with_masks, disc_mask)\n",
    "    display_overlay(original_image, image_with_masks, cup_mask, disc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth classifications from CSV file\n",
    "ground_truth_dict = {}\n",
    "csv_file = \"Glaucoma_Balanced_Dataset/Preprocessed_images_input_to_bound/bounding_box_labels_adjusted_CDR_CSV.csv\"\n",
    "with open(csv_file, mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row\n",
    "    for row in reader:\n",
    "        if row[5] == 'NRG':\n",
    "            ground_truth_dict[row[0]] = 0  # Not Glaucoma\n",
    "        elif row[5] == 'RG':\n",
    "            ground_truth_dict[row[0]] = 1  # Glaucoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diameters(cup_mask, disc_mask):\n",
    "   # Calculate the contour of the segmented cup mask\n",
    "    cup_contours, _ = cv2.findContours(cup_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Calculate the contour of the segmented disc mask\n",
    "    disc_contours, _ = cv2.findContours(disc_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the largest contour for optic cup\n",
    "    cup_contour = max(cup_contours, key=cv2.contourArea)\n",
    "    # Find the largest contour for optic disk\n",
    "    disc_contour = max(disc_contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Calculate the diameter of optic cup\n",
    "    _, _, cup_width, cup_height = cv2.boundingRect(cup_contour)\n",
    "    cup_diameter = max(cup_width, cup_height)\n",
    "    \n",
    "    # Calculate the diameter of optic disk\n",
    "    _, _, disc_width, disc_height = cv2.boundingRect(disc_contour)\n",
    "    disc_diameter = max(disc_width, disc_height)\n",
    "    \n",
    "    return cup_diameter, disc_diameter\n",
    "\n",
    "# Calculate cup and disk diameters and CDR values\n",
    "optic_cup_diameters = []\n",
    "optic_disc_diameters = []\n",
    "for cup_mask, disc_mask in zip(cup_masks, disc_masks):\n",
    "    cup_diameter, disc_diameter = calculate_diameters(cup_mask, disc_mask)\n",
    "    optic_cup_diameters.append(cup_diameter)\n",
    "    optic_disc_diameters.append(disc_diameter)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)  # Assuming X is a list of images\n",
    "optic_cup_diameters = np.array(optic_cup_diameters)\n",
    "optic_disc_diameters = np.array(optic_disc_diameters)\n",
    "\n",
    "# Calculate CDR\n",
    "#cdr_values = [cup_diameter / disk_diameter for cup_diameter, disk_diameter in zip(optic_cup_diameters, optic_disk_diameters)]\n",
    "\n",
    "# Calculate CDR\n",
    "cdr_values = optic_cup_diameters / optic_disc_diameters\n",
    "\n",
    "# Convert CDR values to binary labels\n",
    "y = np.where(cdr_values > 0.65, 1, 0)\n",
    "\n",
    "# Convert CDR values to binary labels\n",
    "# y = [1 if cdr > 0.65 else 0 for cdr in cdr_values]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
