{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4335c712-04cf-466c-b132-60e91f7cb525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Written by Diana Lewis \n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca60c47e-a45e-40ab-a408-a1d1c8fb6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to overlay segmented masks on images\n",
    "def overlay_masks(image, cup_mask, disk_mask):\n",
    "    overlay = image.copy()\n",
    "    overlay[cup_mask != 0] = [0, 255, 0]  # Green color for cup mask\n",
    "    overlay[disk_mask != 0] = [0, 0, 255]  # Red color for disk mask\n",
    "    return cv2.addWeighted(overlay, 0.5, image, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8868e2b4-7a72-4f35-a4c6-d217ee4adac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth classifications from CSV file\n",
    "ground_truth_dict = {}\n",
    "csv_file = \"Glaucoma_Balanced_Dataset/Preprocessed_images_input_to_bound/bounding_box_labels_adjusted_CDR_CSV.csv\"\n",
    "with open(csv_file, mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row\n",
    "    for row in reader:\n",
    "        if row[5] == 'NRG':\n",
    "            ground_truth_dict[row[0]] = 0  # Not Glaucoma\n",
    "        elif row[5] == 'RG':\n",
    "            ground_truth_dict[row[0]] = 1  # Glaucoma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c8ef71e-b9c8-4050-b2be-d04cac49d7c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segmented_cup_masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m optic_cup_diameters \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m optic_disk_diameters \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cup_mask, disk_mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(segmented_cup_masks, segmented_disk_masks):\n\u001b[1;32m     28\u001b[0m     cup_diameter, disk_diameter \u001b[38;5;241m=\u001b[39m calculate_diameters(cup_mask, disk_mask)\n\u001b[1;32m     29\u001b[0m     optic_cup_diameters\u001b[38;5;241m.\u001b[39mappend(cup_diameter)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'segmented_cup_masks' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to calculate optic cup and optic disk diameters from segmented masks\n",
    "#Need to call from segmented_cup_mask and segmented_disk_mask from ROI-FCN-GNET-Use-This.ipynb\n",
    "def calculate_diameters(segmented_cup_mask, segmented_disk_mask):\n",
    "    # Calculate the contour of the segmented cup mask\n",
    "    _, cup_contours, _ = cv2.findContours(segmented_cup_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Calculate the contour of the segmented disk mask\n",
    "    _, disk_contours, _ = cv2.findContours(segmented_disk_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the largest contour for optic cup\n",
    "    cup_contour = max(cup_contours, key=cv2.contourArea)\n",
    "    # Find the largest contour for optic disk\n",
    "    disk_contour = max(disk_contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Calculate the diameter of optic cup\n",
    "    _, _, cup_width, cup_height = cv2.boundingRect(cup_contour)\n",
    "    cup_diameter = max(cup_width, cup_height)\n",
    "    \n",
    "    # Calculate the diameter of optic disk\n",
    "    _, _, disk_width, disk_height = cv2.boundingRect(disk_contour)\n",
    "    disk_diameter = max(disk_width, disk_height)\n",
    "    \n",
    "    return cup_diameter, disk_diameter\n",
    "\n",
    "# Calculate cup and disk diameters and CDR values\n",
    "optic_cup_diameters = []\n",
    "optic_disk_diameters = []\n",
    "for cup_mask, disk_mask in zip(segmented_cup_masks, segmented_disk_masks):\n",
    "    cup_diameter, disk_diameter = calculate_diameters(cup_mask, disk_mask)\n",
    "    optic_cup_diameters.append(cup_diameter)\n",
    "    optic_disk_diameters.append(disk_diameter)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)  # Assuming X is a list of images\n",
    "optic_cup_diameters = np.array(optic_cup_diameters)\n",
    "optic_disk_diameters = np.array(optic_disk_diameters)\n",
    "\n",
    "# Calculate CDR\n",
    "#cdr_values = [cup_diameter / disk_diameter for cup_diameter, disk_diameter in zip(optic_cup_diameters, optic_disk_diameters)]\n",
    "\n",
    "# Calculate CDR\n",
    "cdr_values = optic_cup_diameters / optic_disk_diameters\n",
    "\n",
    "# Convert CDR values to binary labels\n",
    "y = np.where(cdr_values > 0.65, 1, 0)\n",
    "\n",
    "# Convert CDR values to binary labels\n",
    "# y = [1 if cdr > 0.65 else 0 for cdr in cdr_values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3efede5-476a-4f24-bf45-e18a1a3dd132",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m optic_disk_diameters \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m cdr_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, cup_mask, disk_mask \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m      6\u001b[0m     cup_diameter, disk_diameter \u001b[38;5;241m=\u001b[39m calculate_diameters(cup_mask, disk_mask)\n\u001b[1;32m      7\u001b[0m     optic_cup_diameters\u001b[38;5;241m.\u001b[39mappend(cup_diameter)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val, cdr_train, cdr_val = train_test_split(X, y, cdr_values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the images and overlay the segmentation masks\n",
    "def preprocess_image(image, cup_mask, disk_mask):\n",
    "    Resize the image and masks\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    cup_mask = cv2.resize(cup_mask, (224, 224))\n",
    "    disk_mask = cv2.resize(disk_mask, (224, 224))\n",
    "    #Overlay the masks on the image\n",
    "    return overlay_masks(image, cup_mask, disk_mask)\n",
    "\n",
    "X_train = [preprocess_image(X_train[i], segmented_cup_masks[i], segmented_disk_masks[i]) for i in range(len(X_train))]\n",
    "X_val = [preprocess_image(X_val[i], segmented_cup_masks[i], segmented_disk_masks[i]) for i in range(len(X_val))]\n",
    "\n",
    "# Load MobileNetV3Small model\n",
    "base_model = tf.keras.applications.MobileNetV3Small(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "input_image = tf.keras.Input(shape=(224, 224, 3))\n",
    "base_model_output = base_model(input_image)\n",
    "global_avg_pooling_output = tf.keras.layers.GlobalAveragePooling2D()(base_model_output)\n",
    "cdr_input = tf.keras.Input(shape=(1,))\n",
    "concatenated_input = tf.keras.layers.Concatenate()([global_avg_pooling_output, cdr_input])\n",
    "dense_output = tf.keras.layers.Dense(1, activation='sigmoid')(concatenated_input)\n",
    "model = tf.keras.Model(inputs=[input_image, cdr_input], outputs=dense_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit([np.array(X_train), cdr_train], y_train, epochs=10, validation_data=([np.array(X_val), cdr_val], y_val))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict([np.array(X_val), cdr_val])\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Compare predicted CDR values with ground truth classifications\n",
    "for i in range(len(y_val)):\n",
    "    image_name = os.path.basename(X_val[i])  # Assuming X_val contains image paths\n",
    "    ground_truth = ground_truth_dict.get(image_name, \"Unknown\")\n",
    "    print(f\"Image: {image_name}, Ground Truth: {ground_truth}, Predicted CDR: {y_pred[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8348a-5d07-484a-844f-4750b28c22d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08447f-309f-44ad-bf8f-e324120f444f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
