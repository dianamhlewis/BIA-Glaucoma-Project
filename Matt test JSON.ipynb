{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89192fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Obtaining dependency information for opencv-python-headless from https://files.pythonhosted.org/packages/20/44/458a0a135866f5e08266566b32ad9a182a7a059a894effe6c41a9c841ff1/opencv_python_headless-4.9.0.80-cp37-abi3-win_amd64.whl.metadata\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\matt\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Downloading opencv_python_headless-4.9.0.80-cp37-abi3-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.5 MB 653.6 kB/s eta 0:00:59\n",
      "   ---------------------------------------- 0.1/38.5 MB 1.4 MB/s eta 0:00:28\n",
      "   ---------------------------------------- 0.4/38.5 MB 2.5 MB/s eta 0:00:16\n",
      "    --------------------------------------- 0.9/38.5 MB 4.6 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.6/38.5 MB 6.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.7/38.5 MB 9.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 3.9/38.5 MB 11.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.1/38.5 MB 13.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 6.4/38.5 MB 15.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 7.8/38.5 MB 16.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 9.3/38.5 MB 18.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 10.8/38.5 MB 27.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 12.5/38.5 MB 29.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 14.3/38.5 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 16.0/38.5 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 18.1/38.5 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 20.3/38.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 22.6/38.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 24.8/38.5 MB 46.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 25.3/38.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 28.8/38.5 MB 46.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.6/38.5 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.2/38.5 MB 43.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.0/38.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.9/38.5 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.6/38.5 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.5 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.5 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 28.4 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.9.0.80\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install opencv-python-headless numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9303758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52e07f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Process each annotation (e.g., extract label and ellipse coordinates)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m image_annotations:\n\u001b[1;32m---> 15\u001b[0m     label \u001b[38;5;241m=\u001b[39m ann[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Get annotation label (e.g., \"Optic Disc\" or \"Optic Cup\")\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     ellipse_points \u001b[38;5;241m=\u001b[39m ann[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Get ellipse coordinates\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Further processing based on your requirements\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# (e.g., generate binary masks, perform analysis, etc.)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Example: Print image path and annotations\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load annotations from exported JSON file\n",
    "json_file_path = 'Glaucoma_Balanced_Dataset/Label_Studio_Output/project-6-at-2024-04-13-17-30-d38cba62.json'  # Update with your file path\n",
    "with open(json_file_path, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Access and process annotations\n",
    "for annotation in annotations:\n",
    "    image_path = annotation['data']['image']  # Get image path\n",
    "    image_annotations = annotation['annotations']  # Get annotations for the image\n",
    "    \n",
    "    # Process each annotation (e.g., extract label and ellipse coordinates)\n",
    "    for ann in image_annotations:\n",
    "        label = ann['result'][0]['value']['label']  # Get annotation label (e.g., \"Optic Disc\" or \"Optic Cup\")\n",
    "        ellipse_points = ann['result'][0]['value']['points']  # Get ellipse coordinates\n",
    "        \n",
    "        # Further processing based on your requirements\n",
    "        # (e.g., generate binary masks, perform analysis, etc.)\n",
    "\n",
    "    # Example: Print image path and annotations\n",
    "    print(f\"Image Path: {image_path}\")\n",
    "    print(f\"Annotations: {image_annotations}\")\n",
    "\n",
    "# Further processing of annotations based on your specific use case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8814c347",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'bitwise_and'\n> Overload resolution failed:\n>  - src2 data type = object is not supported\n>  - Expected Ptr<cv::UMat> for argument 'src2'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mellipse(mask, (x_center, y_center), (major_axis, minor_axis), angle, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m360\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Apply the mask on the original image\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m masked_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbitwise_and(image, mask)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Display the original image and masked image\u001b[39;00m\n\u001b[0;32m     53\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Image\u001b[39m\u001b[38;5;124m'\u001b[39m, image)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'bitwise_and'\n> Overload resolution failed:\n>  - src2 data type = object is not supported\n>  - Expected Ptr<cv::UMat> for argument 'src2'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to your exported JSON file\n",
    "json_file_path = 'Glaucoma_Balanced_Dataset/Label_Studio_Output/project-6-at-2024-04-13-17-39-38398e03.json'  # Update with your file path\n",
    "\n",
    "# Load annotations from the JSON file\n",
    "with open(json_file_path, 'r') as f:\n",
    "    annotations_data = json.load(f)\n",
    "\n",
    "# Process annotations and display masks on original images\n",
    "for item in annotations_data:\n",
    "    # Extract image path and annotations\n",
    "    image_path = item['data']['image']\n",
    "    image_annotations = item['annotations']\n",
    "\n",
    "    # Load the original image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Create a mask image initialized with zeros (black)\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    # Process each annotation for the image\n",
    "    for annotation in image_annotations:\n",
    "        # Get annotation results (handle missing keys gracefully)\n",
    "        results = annotation.get('result', [])\n",
    "\n",
    "        # Iterate through each result (in case multiple results are present)\n",
    "        for result in results:\n",
    "            # Get value dictionary\n",
    "            value = result.get('value', {})\n",
    "            \n",
    "            # Extract label and points\n",
    "            label = value.get('label')\n",
    "            ellipse_points = value.get('points', [])\n",
    "\n",
    "            # Check if label and points are valid\n",
    "            if label in ['Optic Disc', 'Optic Cup'] and len(ellipse_points) == 2:\n",
    "                # Convert ellipse points to tuple format (x_center, y_center, major_axis_length, minor_axis_length, angle)\n",
    "                x_center, y_center = ellipse_points[0]['x'], ellipse_points[0]['y']\n",
    "                major_axis = ellipse_points[1]['x'] - ellipse_points[0]['x']\n",
    "                minor_axis = ellipse_points[1]['y'] - ellipse_points[0]['y']\n",
    "                angle = 0.0  # Assuming angle is not provided in Label Studio annotations\n",
    "\n",
    "                # Draw ellipse (mask) on the mask image\n",
    "                cv2.ellipse(mask, (x_center, y_center), (major_axis, minor_axis), angle, 0, 360, (255, 255, 255), -1)\n",
    "\n",
    "    # Apply the mask on the original image\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "\n",
    "    # Display the original image and masked image\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Masked Image', masked_image)\n",
    "    cv2.waitKey(0)  # Wait for any key press to close the windows\n",
    "\n",
    "# Close all OpenCV windows after processing\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4743700",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Create a mask image initialized with zeros (black)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(image\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Process each annotation for the image\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m annotation \u001b[38;5;129;01min\u001b[39;00m image_annotations:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Get annotation results (handle missing keys gracefully)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to your exported JSON file\n",
    "#json_file_path = 'Glaucoma_Balanced_Dataset/Label_Studio_Output/project-6-at-2024-04-13-17-30-d38cba62.json'\n",
    "\n",
    "# Load annotations from the JSON file\n",
    "with open(json_file_path, 'r') as f:\n",
    "    annotations_data = json.load(f)\n",
    "\n",
    "# Process annotations and display masks on original images\n",
    "for item in annotations_data:\n",
    "    # Extract image path and annotations\n",
    "    image_path = item['data']['image']\n",
    "    image_annotations = item['annotations']\n",
    "\n",
    "    # Load the original image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Create a mask image initialized with zeros (black)\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Process each annotation for the image\n",
    "    for annotation in image_annotations:\n",
    "        # Get annotation results (handle missing keys gracefully)\n",
    "        results = annotation.get('result', [])\n",
    "\n",
    "        # Iterate through each result (in case multiple results are present)\n",
    "        for result in results:\n",
    "            # Get value dictionary\n",
    "            value = result.get('value', {})\n",
    "            \n",
    "            # Extract label and points\n",
    "            label = value.get('label')\n",
    "            ellipse_points = value.get('points', [])\n",
    "\n",
    "            # Check if label and points are valid\n",
    "            if label in ['Optic Disc', 'Optic Cup'] and len(ellipse_points) == 2:\n",
    "                # Convert ellipse points to tuple format (x_center, y_center, major_axis_length, minor_axis_length, angle)\n",
    "                x_center, y_center = ellipse_points[0]['x'], ellipse_points[0]['y']\n",
    "                major_axis = ellipse_points[1]['x'] - ellipse_points[0]['x']\n",
    "                minor_axis = ellipse_points[1]['y'] - ellipse_points[0]['y']\n",
    "                angle = 0.0  # Assuming angle is not provided in Label Studio annotations\n",
    "\n",
    "                # Draw ellipse (mask) on the mask image\n",
    "                cv2.ellipse(mask, (x_center, y_center), (major_axis, minor_axis), angle, 0, 360, 255, -1)\n",
    "\n",
    "    # Apply the mask on the original image using bitwise_and\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Display the original image and masked image\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Masked Image', masked_image)\n",
    "    cv2.waitKey(0)  # Wait for any key press to close the windows\n",
    "\n",
    "# Close all OpenCV windows after processing\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae05fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to load image '/data/upload/6/b7cf3c43-enhanced_TRAIN000000.jpg'\n",
      "Error: Unable to load image '/data/upload/6/117ce50b-enhanced_TRAIN000001.jpg'\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Wait for any key press to close the windows\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Close all OpenCV windows after processing\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to your exported JSON file\n",
    "#json_file_path = 'Glaucoma_Balanced_Dataset/Label_Studio_Output/project-6-at-2024-04-13-17-30-d38cba62.json'\n",
    "\n",
    "# Load annotations from the JSON file\n",
    "with open(json_file_path, 'r') as f:\n",
    "    annotations_data = json.load(f)\n",
    "\n",
    "# Process annotations and display masks on original images\n",
    "for item in annotations_data:\n",
    "    # Extract image path and annotations\n",
    "    image_path = item['data']['image']\n",
    "    image_annotations = item['annotations']\n",
    "\n",
    "    # Load the original image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Check if image is loaded successfully\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image '{image_path}'\")\n",
    "        continue  # Skip to the next image if loading fails\n",
    "\n",
    "    # Create a mask image initialized with zeros (black)\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Process each annotation for the image\n",
    "    for annotation in image_annotations:\n",
    "        # Get annotation results (handle missing keys gracefully)\n",
    "        results = annotation.get('result', [])\n",
    "\n",
    "        # Iterate through each result (in case multiple results are present)\n",
    "        for result in results:\n",
    "            # Get value dictionary\n",
    "            value = result.get('value', {})\n",
    "            \n",
    "            # Extract label and points\n",
    "            label = value.get('label')\n",
    "            ellipse_points = value.get('points', [])\n",
    "\n",
    "            # Check if label and points are valid\n",
    "            if label in ['Optic Disc', 'Optic Cup'] and len(ellipse_points) == 2:\n",
    "                # Convert ellipse points to tuple format (x_center, y_center, major_axis_length, minor_axis_length, angle)\n",
    "                x_center, y_center = ellipse_points[0]['x'], ellipse_points[0]['y']\n",
    "                major_axis = ellipse_points[1]['x'] - ellipse_points[0]['x']\n",
    "                minor_axis = ellipse_points[1]['y'] - ellipse_points[0]['y']\n",
    "                angle = 0.0  # Assuming angle is not provided in Label Studio annotations\n",
    "\n",
    "                # Draw ellipse (mask) on the mask image\n",
    "                cv2.ellipse(mask, (x_center, y_center), (major_axis, minor_axis), angle, 0, 360, 255, -1)\n",
    "\n",
    "    # Apply the mask on the original image using bitwise_and\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Display the original image and masked image\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Masked Image', masked_image)\n",
    "    cv2.waitKey(0)  # Wait for any key press to close the windows\n",
    "\n",
    "# Close all OpenCV windows after processing\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf548471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
