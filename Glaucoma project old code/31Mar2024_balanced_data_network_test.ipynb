{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41e76e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updates on this code:\n",
    "# it is able to adjust the number of images we want to use\n",
    "# adds functionality to check for corrupted images (one of the images is corrupted and I don't know which yet)\n",
    "\n",
    "#Potential problems:\n",
    "# the image preprocessing is done as a code line that may have to be run again\n",
    "# It would probably be better to run our preprocessing on all the images separately and potentially save them as new images\n",
    "# Probably best to do this after we crop out everything but the optic disk\n",
    "\n",
    "# There's also no current way to pause tensor flow or any of the processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3121ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code written by Matthew Miller (adapted from chatGPT and prior code from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9266cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7a3e7",
   "metadata": {},
   "source": [
    "## Set the image folder and read the CSV file (the CSV files and the images must be in a single folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89636848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glaucoma_Balanced_Dataset/JustRAIGS\\JustRAIGS_Train_labels_balance.csv\n"
     ]
    }
   ],
   "source": [
    "# Folder containing the image files and the corresponding CSV file\n",
    "folder_path = \"Glaucoma_Balanced_Dataset/JustRAIGS\"\n",
    "csv_file = \"JustRAIGS_Train_labels_balance.csv\"\n",
    "csv_path = os.path.join(folder_path,csv_file)\n",
    "print(csv_path)\n",
    "\n",
    "# Read the CSV file containing the image filenames and classifications\n",
    "data = pd.read_csv(csv_path)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269e52a7",
   "metadata": {},
   "source": [
    "## !!!!!!!  CAUTION  !!!!!!! DO NOT RUN WITH A LARGE NUMBER OF DATA FILES IF YOU DON'T WANT TO WAIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "860a8c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image file not found: Glaucoma_Balanced_Dataset/JustRAIGS\\TRAIN000426.jpg\n"
     ]
    }
   ],
   "source": [
    "# Define the number of random images to select\n",
    "num_random_images = 2500  # Change this number as needed from 2 to 6540\n",
    "\n",
    "\n",
    "# Define empty lists to store the image data and corresponding classifications\n",
    "images = []\n",
    "classifications = []\n",
    "\n",
    "# Define the target size for resizing the images\n",
    "## This step is limiting our resolution, probably way too aggressive eventually, but fine for testing\n",
    "target_size = (100, 100)  # Adjust the size as needed\n",
    "\n",
    "#target_size = (1944, 1944)  # this should make the images square initally and size down to the most common\n",
    "#smallest dimension for a few of the images.\n",
    "#Going larger may force interpolation, which wouldn't be ideal.\n",
    "# this method is also distorting the aspect ratio, but that won't matter later since the optic disk is what we care about,\n",
    "#and we can define a constant size for that after preprocessing\n",
    "\n",
    "# Shuffle the rows in the DataFrame to ensure randomness\n",
    "data_shuffled = data.sample(frac=1)\n",
    "\n",
    "\n",
    "# Iterate over each row in the CSV file\n",
    "for index, row in data_shuffled.head(num_random_images).iterrows():\n",
    "    # Read the image file\n",
    "    image_filename = row['Eye ID']  + \".jpg\" # The column containing the image filenames\n",
    "    #print(image_filename)\n",
    "    image_path = os.path.join(folder_path, image_filename)\n",
    "    #print(image_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Check if the image file exists\n",
    "    if os.path.exists(image_path):\n",
    "        # Load the image\n",
    "    \n",
    "    \n",
    "        image = cv2.imread(image_path)  # Use cv2.imread for reading images\n",
    "    \n",
    "    \n",
    "        # Check if the image was loaded successfully\n",
    "        if image is not None: \n",
    "    \n",
    "            # Preprocess the image as necessary (e.g., resizing, hist eq, normalization)  \n",
    "            # Preprocess the image by resizing it to the target size\n",
    "            image_resized = cv2.resize(image, target_size)\n",
    "\n",
    "\n",
    "            b, g, r = cv2.split(image_resized)\n",
    "            # Perform histogram equalization and normalization on each channel\n",
    "            b_eq = cv2.equalizeHist(b)\n",
    "            g_eq = cv2.equalizeHist(g)\n",
    "            r_eq = cv2.equalizeHist(r)\n",
    "            # Merge the equalized channels back into a color image\n",
    "            image_eq = cv2.merge((b_eq, g_eq, r_eq))\n",
    "\n",
    "            # Normalize the image intensity values\n",
    "            image_eq = cv2.normalize(image_eq, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "\n",
    "            # Add the preprocessed image to the images list\n",
    "            images.append(image_eq)\n",
    "\n",
    "            # Display the image if testing is necessary(RGB stuff is so the images display with right colors (BGR to RGB))\n",
    "            #image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)\n",
    "            #plt.imshow(image_rgb)\n",
    "            #plt.show()\n",
    "\n",
    "            # Get the classification label\n",
    "            classification = row['Final Label']  # Assuming 'Classification' is the column containing the classifications\n",
    "            classifications.append(classification)\n",
    "            \n",
    "        else:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "    else:\n",
    "        print(f\"Image file not found: {image_path}\") \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07f80bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to numpy arrays for further processing\n",
    "images = np.array(images)\n",
    "#print(images)\n",
    "\n",
    "#This next line works correctly for reading the classifications\n",
    "classifications = np.array(classifications)\n",
    "#print(classifications)\n",
    "# Now you can use the images and classifications for training your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04fe6bb",
   "metadata": {},
   "source": [
    "## Need to split the data now into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa0058fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1999\n",
      "Number of validation samples: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "#0.2 is setting the validation data size to 20% of the total (80/20 split) and the random state is the seed\n",
    "#This is randomly picking data points, which is good\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, classifications, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the sizes of the training and validation sets\n",
    "print(\"Number of training samples:\", len(X_train))\n",
    "print(\"Number of validation samples:\", len(X_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bece81",
   "metadata": {},
   "source": [
    "## This is our neural network, the parameters and network architecture are just an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c49a3",
   "metadata": {},
   "source": [
    "## This is running a little too quickly rn, we might need more layers or depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdcf2be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - accuracy: 0.5293 - loss: 19.7085 - val_accuracy: 0.6060 - val_loss: 0.6770\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5904 - loss: 0.6816\n",
      "Validation accuracy: 0.6060000061988831\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Build the Neural Network Model\n",
    "#change the image height and width (100x100 for this example to fit the output of the preprocessed images above)\n",
    "#make the image height equal to the image width for the future\n",
    "\n",
    "image_height = 100\n",
    "image_width = 100\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Step 4: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the Model\n",
    "#history = model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=1, validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "#test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "#print('Test accuracy:', test_acc)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(\"Validation accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3aaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
