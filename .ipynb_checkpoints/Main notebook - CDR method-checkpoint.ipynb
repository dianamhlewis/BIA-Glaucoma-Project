{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad94a995",
   "metadata": {},
   "source": [
    "# Each of the markdown sections below will be a separate code file (function notebook)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8431b723",
   "metadata": {},
   "source": [
    "## The \"Preprocessing on 30 images for input to Label Studio\" code file is used for the input to the label studio bounding boxes.\n",
    "## This code does not need to be run here, since that external software would have to be used again for the bounding boxes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ad7f058",
   "metadata": {},
   "source": [
    "## The \"Read csv file to move jpg files 29Mar2024\" code file was also used to balance the data set\n",
    "## and overcome the 2 GB push limit for github by moving images from one folder to another based on a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849387e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## put all the modules we have used up here possibly (numpy,matplotlib, etc)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88210f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this imports all the functions in the corresponding code file\n",
    "\n",
    "%run image_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcca9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Watershed_Method.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9297ed90",
   "metadata": {},
   "source": [
    "##Set the folderpath for the FCN bounded images and for the csv with the bounding box coordinates\n",
    "bounding_box_folder_path = \"Glaucoma_Balanced_Dataset/Preprocessed_images_input_to_bound\"\n",
    "bound_csv_file = \"Glaucoma30_bounding_boxes_06Apr2024.csv\"\n",
    "bound_csv_path = os.path.join(bounding_box_folder_path,bound_csv_file)\n",
    "print(bound_csv_path)\n",
    "\n",
    "# Read the CSV file containing the image filenames and classifications\n",
    "data = pd.read_csv(bound_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a1623",
   "metadata": {},
   "source": [
    "## Train the FCN (these images were already preprocessed and bounded using Label Studio (Just run the output of Diana's code with this block, so that we get the trained network out)\n",
    "\n",
    "This might be 2 separate FCNs with the same architecture, or one that can train on both\n",
    "2 separate identical is easier to code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run FCN-Segmentation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c975479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the FCN to the rest of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92403354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glaucoma_Balanced_Dataset/JustRAIGS\\JustRAIGS_Train_labels_balance.csv\n"
     ]
    }
   ],
   "source": [
    "## Set the folder path for the balanced dataset\n",
    "## set the filename for the balanced data csv file\n",
    "\n",
    "\n",
    "# Folder containing the image files and the corresponding CSV file\n",
    "folder_path = \"Glaucoma_Balanced_Dataset/JustRAIGS\"\n",
    "csv_file = \"JustRAIGS_Train_labels_balance.csv\"\n",
    "csv_path = os.path.join(folder_path,csv_file)\n",
    "print(csv_path)\n",
    "\n",
    "# Read the CSV file containing the image filenames and classifications\n",
    "data = pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57574ab7",
   "metadata": {},
   "source": [
    "## do the preprocessing on the balanced dataset (cropping & resizing, hist eq, normalization) [possibly repeat this step and break it into 2 steps for the ability to upload on github)\n",
    "\n",
    "if we include cropping in this step, we can just output the final cropped images, and this may keep us below the github 2 gb limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a20e4589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed images: 10\n"
     ]
    }
   ],
   "source": [
    "# Specify the desired output size (e.g., 1956 x 1725)\n",
    "target_width = 2048\n",
    "target_height = 1024\n",
    "\n",
    "#The number of images will be randomly shuffled through and images can't be selected twice (not put back)\n",
    "num_images = 10\n",
    "\n",
    "\n",
    "# Process images and get a list of processed images (as NumPy arrays)\n",
    "processed_images = process_images_from_csv(data, folder_path, target_width, target_height, num_images)\n",
    "\n",
    "# Print the number of processed images (just for testing purposes)\n",
    "print(f\"Number of processed images: {len(processed_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42651aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For testing purposes only\n",
    "##ONLY RUN THIS FOR LESS THAN 15 IMAGES, IT WILL DISPLAY ALL THE IMAGES\n",
    "\n",
    "##This code block will be useful in applying this output later for the FCN step if we want\n",
    "\n",
    "\n",
    "# Example: Access and work with the processed images\n",
    "for idx, img_array in enumerate(processed_images):\n",
    "    # Convert BGR to RGB (assuming img_array is in BGR format)\n",
    "    image_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the processed image using matplotlib\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(f\"Processed Image {idx + 1}\")  # Set title\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a297",
   "metadata": {},
   "source": [
    "## Use trained FCN to make an cup and a disk on each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bb8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FCN should export cropped images (write them to jpg so we have a saved step)\n",
    "\n",
    "#make sure to keep the filenames exactly the same\n",
    "\n",
    "## copy and paste the csv file with the classifications, or fix the code to be able to work with the images and csv files being in different folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541a6c5",
   "metadata": {},
   "source": [
    "## calculate the CDR for each image, and determine whether it is above or below the threshold for glaucoma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d0afb",
   "metadata": {},
   "source": [
    "## Validate the performance with the expert opinions provided in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97875e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
